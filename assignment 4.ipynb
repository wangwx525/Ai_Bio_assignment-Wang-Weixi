{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from glob import glob\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=r'C:\\Users\\win10\\Desktop\\6207\\BS6207-assignment4'\n",
    "artifacts_dir=\"artifacts\"\n",
    "cancer_regions='cancer_regions'\n",
    "normal_regions='normal_regions'\n",
    "other='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\win10\\\\Desktop\\\\6207\\\\BS6207-assignment4\\\\new\\\\testSet'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir=os.path.join(data_dir,'new','trainSet')\n",
    "valid_dir=os.path.join(data_dir,'new','validSet')\n",
    "test_dir=os.path.join(data_dir,'new','testSet')\n",
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "train_transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#generate dataloader\n",
    "train_ds=ImageFolder(train_dir,transform=train_transform)\n",
    "valid_ds=ImageFolder(valid_dir,transform=test_transform)\n",
    "test_ds=ImageFolder(test_dir,transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\t# 这里会存储迄今最优模型的参数\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            #BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            #BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            #BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            #BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            #BatchNorm2d(4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fully_c = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512 * 4 * 4, 4096),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024,4),\n",
    "        )\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fully_c(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 4, 4]         295,168\n",
      "      BatchNorm2d-10            [-1, 256, 4, 4]             512\n",
      "             ReLU-11            [-1, 256, 4, 4]               0\n",
      "        MaxPool2d-12            [-1, 256, 2, 2]               0\n",
      "          Flatten-13                 [-1, 1024]               0\n",
      "           Linear-14                  [-1, 512]         524,800\n",
      "             ReLU-15                  [-1, 512]               0\n",
      "           Linear-16                    [-1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 898,564\n",
      "Trainable params: 898,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 7.43\n",
      "Params size (MB): 3.43\n",
      "Estimated Total Size (MB): 11.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=Model()\n",
    "summary(model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,valid_iter,optim,epoches,early_stop=False,name=None):\n",
    "    history_loss=dict()\n",
    "    history_acc=dict()\n",
    "    history_loss[\"val\"]=[]\n",
    "    history_loss[\"train\"]=[]\n",
    "        \n",
    "    history_acc[\"val\"]=[]\n",
    "    history_acc[\"train\"]=[]\n",
    "    best_acc=0\n",
    "    for epoch in range(epoches):\n",
    "        print(\"processing the {} epoch\".format(epoch))\n",
    "        epoch_start_time = time.time()\n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        val_acc = []\n",
    "        val_loss = []\n",
    "        len_train=0\n",
    "        net.train()\n",
    "        for batch_x,batch_y in train_iter:\n",
    "            y_hat=net(batch_x)\n",
    "            l=loss(y_hat,batch_y)\n",
    "            optim.zero_grad()\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "            train_acc.append(np.sum(np.argmax(y_hat.detach().numpy(),axis=1)==batch_y.detach().numpy()))\n",
    "            train_loss.append(l.item())\n",
    "            len_train+=batch_x.shape[0]\n",
    "\n",
    "        train_loss=np.sum(train_loss)/len_train\n",
    "        train_acc=np.sum(train_acc)/len_train\n",
    "        history_loss[\"train\"].append(train_loss)\n",
    "        history_acc[\"train\"].append(train_acc)\n",
    "        #eval\n",
    "        net.eval()\n",
    "        \n",
    "        len_val=0\n",
    "        with torch.no_grad():\n",
    "            for batch_x,batch_y in valid_iter:\n",
    "                y_hat=net(batch_x)\n",
    "                l=loss(y_hat,batch_y)\n",
    "                val_acc.append(np.sum(np.argmax(y_hat.numpy(),axis=1)==batch_y.numpy()))\n",
    "                val_loss.append(l.item())\n",
    "                len_val+=batch_x.shape[0]\n",
    "            \n",
    "        val_loss=np.sum(val_loss)/len_val\n",
    "        val_acc=np.sum(val_acc)/len_val\n",
    "        history_loss[\"val\"].append(val_loss)\n",
    "        history_acc[\"val\"].append(val_acc)\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "                (epoch + 1, epoches, time.time()-epoch_start_time, \\\n",
    "                 train_acc, train_loss, val_acc, val_loss))\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return history_loss,history_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net,test_iter):\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        print(\"processing the {} epoch\".format(epoch))\n",
    "        epoch_start_time = time.time()\n",
    "        #eval\n",
    "        net.eval()\n",
    "        test_acc=[]\n",
    "        test_loss=[]\n",
    "        len_test=0\n",
    "        with torch.no_grad():\n",
    "            for batch_x,batch_y in test_iter:\n",
    "                y_hat=net(batch_x)\n",
    "                l=loss(y_hat,batch_y)\n",
    "                test_acc.append(np.sum(np.argmax(y_hat.numpy(),axis=1)==batch_y.numpy()))\n",
    "                test_loss.append(l.item())\n",
    "                len_test+=batch_x.shape[0]\n",
    "            \n",
    "        test_loss=np.sum(test_loss)/len_test\n",
    "        test_acc=np.sum(test_acc)/len_test\n",
    "        print('[%03d/%03d] %2.2f sec(s) Test Acc: %3.6f Loss: %3.6f' % \\\n",
    "                (epoch + 1, 1, time.time()-epoch_start_time, \\\n",
    "                 test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()\n",
    "optim=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "loss=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the 0 epoch\n",
      "[001/100] 50.58 sec(s) Train Acc: 0.623541 Loss: 0.019073 | Val Acc: 0.711656 loss: 0.007472\n",
      "EarlyStopping counter: 5 out of 10\n",
      "processing the 1 epoch\n",
      "[002/100] 53.71 sec(s) Train Acc: 0.700287 Loss: 0.005842 | Val Acc: 0.720092 loss: 0.005422\n",
      "EarlyStopping counter: 6 out of 10\n",
      "processing the 2 epoch\n",
      "[003/100] 59.28 sec(s) Train Acc: 0.718086 Loss: 0.005394 | Val Acc: 0.735429 loss: 0.005343\n",
      "Validation loss decreased (0.005376 --> 0.005343).  Saving model ...\n",
      "processing the 3 epoch\n",
      "[004/100] 49.22 sec(s) Train Acc: 0.760957 Loss: 0.004756 | Val Acc: 0.711656 loss: 0.008188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "processing the 4 epoch\n",
      "[005/100] 40.90 sec(s) Train Acc: 0.794067 Loss: 0.004226 | Val Acc: 0.373466 loss: 0.013223\n",
      "EarlyStopping counter: 2 out of 10\n",
      "processing the 5 epoch\n",
      "[006/100] 38.93 sec(s) Train Acc: 0.823732 Loss: 0.003813 | Val Acc: 0.611963 loss: 0.018876\n",
      "EarlyStopping counter: 3 out of 10\n",
      "processing the 6 epoch\n",
      "[007/100] 40.88 sec(s) Train Acc: 0.846124 Loss: 0.003278 | Val Acc: 0.787577 loss: 0.005819\n",
      "EarlyStopping counter: 4 out of 10\n",
      "processing the 7 epoch\n",
      "[008/100] 40.66 sec(s) Train Acc: 0.854545 Loss: 0.003135 | Val Acc: 0.836656 loss: 0.004032\n",
      "Validation loss decreased (0.005343 --> 0.004032).  Saving model ...\n",
      "processing the 8 epoch\n",
      "[009/100] 39.34 sec(s) Train Acc: 0.879234 Loss: 0.002709 | Val Acc: 0.714724 loss: 0.005958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "processing the 9 epoch\n",
      "[010/100] 37.83 sec(s) Train Acc: 0.884785 Loss: 0.002538 | Val Acc: 0.732362 loss: 0.010271\n",
      "EarlyStopping counter: 2 out of 10\n",
      "processing the 10 epoch\n",
      "[011/100] 35.77 sec(s) Train Acc: 0.883828 Loss: 0.002704 | Val Acc: 0.768405 loss: 0.013733\n",
      "EarlyStopping counter: 3 out of 10\n",
      "processing the 11 epoch\n",
      "[012/100] 35.62 sec(s) Train Acc: 0.896651 Loss: 0.002286 | Val Acc: 0.891871 loss: 0.002956\n",
      "Validation loss decreased (0.004032 --> 0.002956).  Saving model ...\n",
      "processing the 12 epoch\n",
      "[013/100] 39.34 sec(s) Train Acc: 0.900478 Loss: 0.002220 | Val Acc: 0.916411 loss: 0.002744\n",
      "Validation loss decreased (0.002956 --> 0.002744).  Saving model ...\n",
      "processing the 13 epoch\n",
      "[014/100] 40.12 sec(s) Train Acc: 0.903732 Loss: 0.002137 | Val Acc: 0.594325 loss: 0.014618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "processing the 14 epoch\n",
      "[015/100] 39.98 sec(s) Train Acc: 0.897416 Loss: 0.002336 | Val Acc: 0.861963 loss: 0.003397\n",
      "EarlyStopping counter: 2 out of 10\n",
      "processing the 15 epoch\n",
      "[016/100] 40.00 sec(s) Train Acc: 0.905837 Loss: 0.002120 | Val Acc: 0.875000 loss: 0.003193\n",
      "EarlyStopping counter: 3 out of 10\n",
      "processing the 16 epoch\n",
      "[017/100] 41.33 sec(s) Train Acc: 0.914067 Loss: 0.001973 | Val Acc: 0.858896 loss: 0.002868\n",
      "EarlyStopping counter: 4 out of 10\n",
      "processing the 17 epoch\n",
      "[018/100] 40.49 sec(s) Train Acc: 0.922105 Loss: 0.001723 | Val Acc: 0.843558 loss: 0.004395\n",
      "EarlyStopping counter: 5 out of 10\n",
      "processing the 18 epoch\n",
      "[019/100] 40.70 sec(s) Train Acc: 0.929569 Loss: 0.001614 | Val Acc: 0.864264 loss: 0.003526\n",
      "EarlyStopping counter: 6 out of 10\n",
      "processing the 19 epoch\n",
      "[020/100] 40.40 sec(s) Train Acc: 0.926890 Loss: 0.001649 | Val Acc: 0.855828 loss: 0.003294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "processing the 20 epoch\n",
      "[021/100] 41.18 sec(s) Train Acc: 0.920766 Loss: 0.001779 | Val Acc: 0.886503 loss: 0.002839\n",
      "EarlyStopping counter: 8 out of 10\n",
      "processing the 21 epoch\n",
      "[022/100] 40.41 sec(s) Train Acc: 0.922679 Loss: 0.001779 | Val Acc: 0.398006 loss: 0.022377\n",
      "EarlyStopping counter: 9 out of 10\n",
      "processing the 22 epoch\n",
      "[023/100] 40.19 sec(s) Train Acc: 0.933780 Loss: 0.001492 | Val Acc: 0.785276 loss: 0.007052\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "his_loss,his_acc=train(model, train_loader, valid_loader, optim, 100, early_stop=False,name=\"model_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the 0 epoch\n",
      "[001/001] 1.74 sec(s) Test Acc: 0.680000 Loss: 0.010617\n"
     ]
    }
   ],
   "source": [
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
